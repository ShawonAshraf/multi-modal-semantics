{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26be33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Carina Silberer\"\n",
    "__version__ = \"Multimodal Semantics, IMS Stuttgart, Summer 2023\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf5ce5",
   "metadata": {},
   "source": [
    "*Parts of this notebook are based on those of\n",
    "Christopher Potts' notebook of CS224u, Stanford, Spring 2021.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0ff7c",
   "metadata": {},
   "source": [
    "# Assignment: Transformer-Based Contexual Representation\n",
    "Documentation: https://huggingface.co/transformers/\n",
    "\n",
    "In this notebook, you will be working with RoBERTa's pre-trained contextual embeddings. We will use the [Hugging Face library](https://huggingface.co), its  `transformers` package and the pre-trained model it provides.\n",
    "\n",
    "If you have never worked with transformers, then go through the Warm-Up. Otherwise you can directly jump to the exercise below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773e5fa",
   "metadata": {},
   "source": [
    "## Warm-Up: Basics of `transformers`\n",
    "### Setup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85ee6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ModuleNotFoundError:\n",
    "    !pip install transformers\n",
    "    # Uncomment the line below if you want to use conda for installation\n",
    "finally:\n",
    "    import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ac5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Uncomment the line bbelow if you cannot import torch (or install it using pip):\n",
    "#!conda install -y pytorch torchvision torchaudio -c pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28504f01",
   "metadata": {},
   "source": [
    "### RoBERTa\n",
    "#### Loading the model\n",
    "I recommend to use the base model at least to set up everything. If your computing power is limited, then it may be best to stick to the base model for the final results. Otherwise, you may also compare the base model to the capabilities of the large model, by running both on the same examples. \n",
    "* https://huggingface.co/roberta-base\n",
    "* https://huggingface.co/roberta-large\n",
    "\n",
    "***Example Usage: Masked Language Modelling***\n",
    "\n",
    "*Conveniently, with the pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16cdf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "robertaUnmasker = pipeline('fill-mask', model='roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e218a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1163899302482605,\n",
       "  'token': 410,\n",
       "  'token_str': ' little',\n",
       "  'sequence': \"Hello I'm a little gnome.\"},\n",
       " {'score': 0.04736984893679619,\n",
       "  'token': 5192,\n",
       "  'token_str': ' friendly',\n",
       "  'sequence': \"Hello I'm a friendly gnome.\"},\n",
       " {'score': 0.047068677842617035,\n",
       "  'token': 5671,\n",
       "  'token_str': ' garden',\n",
       "  'sequence': \"Hello I'm a garden gnome.\"},\n",
       " {'score': 0.037068430334329605,\n",
       "  'token': 3034,\n",
       "  'token_str': ' computer',\n",
       "  'sequence': \"Hello I'm a computer gnome.\"},\n",
       " {'score': 0.03495166078209877,\n",
       "  'token': 5262,\n",
       "  'token_str': ' tiny',\n",
       "  'sequence': \"Hello I'm a tiny gnome.\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robertaUnmasker(\"Hello I'm a <mask> gnome.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b94a7",
   "metadata": {},
   "source": [
    "*Or, if you want to, e.g., extract embeddings or use it in any other customised form*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ee42a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "robertaModel = RobertaModel.from_pretrained('roberta-base')\n",
    "robertaModel.eval()\n",
    "# Side note: You will receive a warning which basically tells you that \n",
    "# some weights were randomly initialised (RoBERTa's classification head),\n",
    "# That is, it tells you to finetune the model if you want to use it for \n",
    "# some supervised inference task (which we don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9b70dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4689884",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am a gnome\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = robertaModel(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607e670",
   "metadata": {},
   "source": [
    "**Q:** *What does the output below, `[1, 768]`, mean?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33641656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"pooler_output\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca8201",
   "metadata": {},
   "source": [
    "---\n",
    "#### Basics: Tokenisation\n",
    "Documentation: https://huggingface.co/docs/tokenizers/python/latest/ \n",
    "API: https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#tokenizer\n",
    "Let's see what tokenisation does with an input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e452af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Commonly, koalas are black and white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd8134",
   "metadata": {},
   "source": [
    "The `tokenize` method breaks up the input into 'tokens':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e187876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comm', 'only', ',', 'Ġko', 'al', 'as', 'Ġare', 'Ġblack', 'Ġand', 'Ġwhite']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9299ff",
   "metadata": {},
   "source": [
    "**Q:** *What does the `Ġ` do?*\n",
    "\n",
    "RoBERTa's vocabulary is fixed to a certain number of tokens. Therefore, as you can see above, the tokenizer splits up words that are not part of the vocabulary into smaller subwords and characters ([`word pieces`](https://huggingface.co/transformers/tokenizer_summary.html#wordpiece)). <br/>\n",
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a47e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ban', 'anas']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"bananas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9452c28",
   "metadata": {},
   "source": [
    "---\n",
    "#### Encoding and Decoding Input\n",
    "The `encode` method maps individual strings to indices into the underlying embedding used by the model. Recall, that BERT has the special tokens `[SEP]`, `[CLS]` (and `[MASK]`for the Masked Language Modeling (MLM))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e60161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 33479, 8338, 6, 12546, 337, 281, 32, 909, 8, 1104, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "ex_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465b79c",
   "metadata": {},
   "source": [
    "To see what these tokens look like, we can `convert_ids_to_tokens`, i.e., map the ids back to the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a6272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Comm',\n",
       " 'only',\n",
       " ',',\n",
       " 'Ġko',\n",
       " 'al',\n",
       " 'as',\n",
       " 'Ġare',\n",
       " 'Ġblack',\n",
       " 'Ġand',\n",
       " 'Ġwhite',\n",
       " '</s>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(ex_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4a38f",
   "metadata": {},
   "source": [
    "The `decode` method maps the indices back to individual strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e213f",
   "metadata": {},
   "source": [
    "### Basics of Representations\n",
    "See also the documentation for more details: https://huggingface.co/transformers/model_doc/bert.html#bertmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d64677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Everyone knows that most bananas are yellow.\"\n",
    "ex_ids = tokenizer.encode(sentence, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccb3f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(ex_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07461ac5",
   "metadata": {},
   "source": [
    "With the `forward` method of the model, we can obtain representations for a batch of example inputs. By setting the optional bool `output_hidden_state` to `True`, the hidden states of all layers are returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a151e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    reps = robertaModel(input_ids=torch.tensor([ex_ids]), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b70a66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f6447",
   "metadata": {},
   "source": [
    "The return value `reps` is an instance of a special `transformers` class comprising various representations.<br/>\n",
    "To just get the final output representations for each token, we use `last_hidden_state`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cbc8562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c0399",
   "metadata": {},
   "source": [
    "As we see from the `shape` of the last hidden state, our batch has 1 example, with 10 tokens, where each token is represented by a vector of dimensionality 768. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e15356",
   "metadata": {},
   "source": [
    "**Side note:** The `transformers` models also have a `pooler_output` value. \n",
    "In the case of RoBERTa, this is the output representation above the [CLS] token. Recall, **that this is often used as a summary representation for the entire sequence**, on which basis a classification decision is computed.\n",
    "However, __we cannot use `pooler_output` in the current context__, as `transformers` adds new randomised parameters on top of it, to facilitate fine-tuning. (See also the warning message above when loading the model.)<br/>\n",
    "\n",
    "**If we want the [CLS] representation, we need to use `reps.last_hidden_state[:, 0]`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a648e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state[:, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234b672",
   "metadata": {},
   "source": [
    "Since we set the `output_hidden_state` to `True`, we can access the output representations from each layer of the model by using `hidden_states`. \n",
    "(Setting `output_hidden_state` to `False` would return  `None`.) <br/>\n",
    "There are 13 layers in total for the RoBERTa-base model, the embeddings, followed by the 12 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b4c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reps.hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7a75d",
   "metadata": {},
   "source": [
    "That is,`reps.hidden_states[-1]`would be the same as `reps.hidden_states[12]` for `BERT-base`, and the embeddings can be accessed by `reps.hidden_states[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7fa2c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Everyone knows that most bananas are yellow.</s>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ex_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eedd7ec",
   "metadata": {},
   "source": [
    "## Exercise: Language Perception of Colour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a7884",
   "metadata": {},
   "source": [
    "*We will use the data provided by the coda dataset (for Colour Perception)*\n",
    "https://github.com/nala-cub/coda\n",
    "\n",
    "### Instructions\n",
    "* Run the code below. It loads the underlying coda dataset. We will only use the *object names* and *colours* for this exercise.\n",
    "* Choose 20 object names from different categories (e.g., vegetable/fruits, vehicles, ...).\n",
    "* For each object, determine their typical colours from the given list of colours. This is your personal reference output.\n",
    "* Now, get the top colours that RoBERTa predicts for each of these objects, using the prompts below.\n",
    "  * That is, filter the predictions/scores of RoBERTa to contain only a ranking of the target colour terms we consider. \n",
    "  \n",
    "### Taks\n",
    "1. Compute the accuracy of colour prediction using your small reference data. \n",
    "2. Are there objects for which RoBERTa predicts wrong colours? Why could this be the case?\n",
    "3. Summarise in a few sentences your conclusions regarding the colour knowledge one can learn from language use (i.e., large text corpora). \n",
    "\n",
    "***Submit the following files through ILIAS***:\n",
    "* `ex1_transformers_<yourname>.ipynb`: your completed jupyter notebook\n",
    "* `ex1_transformers_<yourname>.[txt|md]`: a plain text file that contains your answers to Tasks 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f8611e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft\n",
      "Airplane\n",
      "Alarm clock\n",
      "Ambulance\n",
      "Ant\n",
      "Artichoke\n",
      "Apple\n",
      "Apricot\n",
      "Asparagus\n",
      "Auto part\n",
      "Avocado\n",
      "Axe\n",
      "Backpack\n",
      "Bagel\n",
      "Baked goods\n",
      "Ball\n",
      "Balloon\n",
      "Bamboo\n",
      "Banana\n",
      "Band-aid\n",
      "Barrel\n",
      "Baseball bat\n",
      "Baseball glove\n",
      "Basketball (Ball)\n",
      "Bean\n",
      "Bear\n",
      "Bed\n",
      "Bee\n",
      "Beehive\n",
      "Beer\n",
      "Beet\n",
      "Beetle\n",
      "Bell pepper\n",
      "Belt\n",
      "Bench\n",
      "Bicycle\n",
      "Bicycle helmet\n",
      "Bicycle wheel\n",
      "Billboard\n",
      "Billiard table\n",
      "Binoculars\n",
      "Blood\n",
      "Blue jay\n",
      "Blueberry\n",
      "Boat\n",
      "Bomb\n",
      "Bone\n",
      "Book\n",
      "Bookcase\n",
      "Boot\n",
      "Bottle opener\n",
      "Bowl\n",
      "Box\n",
      "Bread\n",
      "Briefcase\n",
      "Broccoli\n",
      "Bronze sculpture\n",
      "Brown bear\n",
      "Building\n",
      "Bull\n",
      "Burrito\n",
      "Bus\n",
      "Bust\n",
      "Butter\n",
      "Butterfly\n",
      "Cabbage\n",
      "Cake\n",
      "Cake stand\n",
      "Calculator\n",
      "Camel\n",
      "Camera\n",
      "Can opener\n",
      "Canary\n",
      "Candle\n",
      "Candy\n",
      "Cannon\n",
      "Canoe\n",
      "Cantaloupe\n",
      "Car\n",
      "Carrot\n",
      "Cassette deck\n",
      "Castle\n",
      "Cat\n",
      "Caterpillar\n",
      "Cattle\n",
      "Cauliflower\n",
      "Ceiling fan\n",
      "Centipede\n",
      "Chainsaw\n",
      "Chair\n",
      "Cheese\n",
      "Cheetah\n",
      "Cherry\n",
      "Chicken\n",
      "Chime\n",
      "Chisel\n",
      "Chocolate\n",
      "Chopsticks\n",
      "Christmas tree\n",
      "Clock\n",
      "Cloud\n",
      "Coal\n",
      "Coat\n",
      "Cocktail\n",
      "Cocktail shaker\n",
      "Coconut\n",
      "Coffee\n",
      "Coffee cup\n",
      "Coffee table\n",
      "Coffeemaker\n",
      "Coin\n",
      "Common sunflower\n",
      "Computer keyboard\n",
      "Computer monitor\n",
      "Computer mouse\n",
      "Cookie\n",
      "Cooking spray\n",
      "Corn\n",
      "Cosmetics\n",
      "Couch\n",
      "Countertop\n",
      "Cowboy hat\n",
      "Crab\n",
      "Cream\n",
      "Crocodile\n",
      "Croissant\n",
      "Crow\n",
      "Crown\n",
      "Crutch\n",
      "Cucumber\n",
      "Curtain\n",
      "Cutting board\n",
      "Dagger\n",
      "Deer\n",
      "Desk\n",
      "Dessert\n",
      "Diaper\n",
      "Dice\n",
      "Dinosaur\n",
      "Dishwasher\n",
      "Dog\n",
      "Doll\n",
      "Dolphin\n",
      "Door\n",
      "Door handle\n",
      "Doughnut\n",
      "Dragonfly\n",
      "Drawer\n",
      "Dress\n",
      "Drill (Tool)\n",
      "Drink\n",
      "Drinking straw\n",
      "Drum\n",
      "Duck\n",
      "Dumbbell\n",
      "Eagle\n",
      "Earrings\n",
      "Egg\n",
      "Egg yolk\n",
      "Eggplant\n",
      "Elephant\n",
      "Emerald\n",
      "Envelope\n",
      "Eraser\n",
      "Fedora\n",
      "Ferret\n",
      "Filing cabinet\n",
      "Fire\n",
      "Fire extinguisher\n",
      "Fire hydrant\n",
      "Fireplace\n",
      "Fish\n",
      "Flag\n",
      "Flamingo\n",
      "Flashlight\n",
      "Flour\n",
      "Flower\n",
      "Flowerpot\n",
      "Flute\n",
      "Flying disc\n",
      "Football\n",
      "Football helmet\n",
      "Footwear\n",
      "Fork\n",
      "Fox\n",
      "French fries\n",
      "Frog\n",
      "Fruit\n",
      "Frying pan\n",
      "Furniture\n",
      "Garlic\n",
      "Gas stove\n",
      "Giraffe\n",
      "Glove\n",
      "Goat\n",
      "Goldfish\n",
      "Golf ball\n",
      "Golf cart\n",
      "Gondola\n",
      "Goose\n",
      "Grape\n",
      "Grapefruit\n",
      "Grasshopper\n",
      "Guacamole\n",
      "Guitar\n",
      "Hair dryer\n",
      "Hamburger\n",
      "Hamster\n",
      "Hand dryer\n",
      "Handbag\n",
      "Handgun\n",
      "Hat\n",
      "Headphones\n",
      "Hedgehog\n",
      "Helicopter\n",
      "Helmet\n",
      "Herb\n",
      "High heels\n",
      "Hippopotamus\n",
      "Honey\n",
      "Honeycomb\n",
      "Horse\n",
      "Hot dog\n",
      "House\n",
      "Houseplant\n",
      "Light bulb\n",
      "Human eye\n",
      "Human hair\n",
      "Ice cream\n",
      "Infant bed\n",
      "Ink\n",
      "Ipod\n",
      "Ivory\n",
      "Jacket\n",
      "Jacuzzi\n",
      "Jade\n",
      "Jaguar (Animal)\n",
      "Jeans\n",
      "Jellyfish\n",
      "Jug\n",
      "Juice\n",
      "Kangaroo\n",
      "Ketchup\n",
      "Kettle\n",
      "Kitchen knife\n",
      "Kite\n",
      "Kiwi\n",
      "Knife\n",
      "Koala\n",
      "Ladder\n",
      "Ladle\n",
      "Ladybug\n",
      "Lagoon\n",
      "Lamp\n",
      "Lantern\n",
      "Laptop\n",
      "Lavender (Plant)\n",
      "Leaf\n",
      "Lemon\n",
      "Leopard\n",
      "Light switch\n",
      "Lighthouse\n",
      "Lily\n",
      "Lime (Fruit)\n",
      "Limousine\n",
      "Lion\n",
      "Lip\n",
      "Lipstick\n",
      "Lizard\n",
      "Lobster\n",
      "Lollipop\n",
      "Loveseat\n",
      "Lynx\n",
      "Mango\n",
      "Marshmallow\n",
      "Mayonnaise\n",
      "Measuring cup\n",
      "Microphone\n",
      "Microwave oven\n",
      "Milk\n",
      "Miniskirt\n",
      "Mixer\n",
      "Mixing bowl\n",
      "Mobile phone\n",
      "Mold\n",
      "Monkey\n",
      "Motorcycle\n",
      "Mouse\n",
      "Muffin\n",
      "Mug\n",
      "Mule\n",
      "Mushroom\n",
      "Musical keyboard\n",
      "Mustard (Food)\n",
      "Nail (Construction)\n",
      "Nail clipper\n",
      "Necklace\n",
      "Nightstand\n",
      "Nut (Food)\n",
      "Olive\n",
      "Onion\n",
      "Orange\n",
      "Ostrich\n",
      "Otter\n",
      "Oven\n",
      "Owl\n",
      "Oyster\n",
      "Paddle\n",
      "Palm tree\n",
      "Pancake\n",
      "Panda\n",
      "Paper cutter\n",
      "Paper towel\n",
      "Parachute\n",
      "Parking meter\n",
      "Parrot\n",
      "Passport\n",
      "Pasta\n",
      "Pastry\n",
      "Pea\n",
      "Peach\n",
      "Peanut butter\n",
      "Pear\n",
      "Peel\n",
      "Pelican\n",
      "Pen\n",
      "Pencil case\n",
      "Segway\n",
      "Pencil sharpener\n",
      "Penguin\n",
      "Peppers\n",
      "Piano\n",
      "Picnic basket\n",
      "Picture frame\n",
      "Pig\n",
      "Pillow\n",
      "Pineapple\n",
      "Pizza\n",
      "Pizza cutter\n",
      "Plant\n",
      "Plastic bag\n",
      "Plate\n",
      "Platter\n",
      "Polar bear\n",
      "Pomegranate\n",
      "Popcorn\n",
      "Porch\n",
      "Porcupine\n",
      "Poster\n",
      "Potato\n",
      "Pretzel\n",
      "Printer\n",
      "Pumpkin\n",
      "Punching bag\n",
      "Rabbit\n",
      "Raccoon\n",
      "Radish\n",
      "Raspberry\n",
      "Rat\n",
      "Raven\n",
      "Refrigerator\n",
      "Remote control\n",
      "Rhinoceros\n",
      "Rice\n",
      "Rifle\n",
      "Ring binder\n",
      "Rock\n",
      "Rocket\n",
      "Rose\n",
      "Rubber ducky\n",
      "Ruby\n",
      "Rugby ball\n",
      "Ruler\n",
      "Salad\n",
      "Salt\n",
      "Sand\n",
      "Sandal\n",
      "Sandwich\n",
      "Saucer\n",
      "Scale\n",
      "Scarf\n",
      "Scissors\n",
      "Scorpion\n",
      "Screwdriver\n",
      "Sea lion\n",
      "Sea turtle\n",
      "Seahorse\n",
      "Seal\n",
      "Seat belt\n",
      "Shark\n",
      "Sheep\n",
      "Shelf\n",
      "Shellfish\n",
      "Shirt\n",
      "Shorts\n",
      "Shotgun\n",
      "Shrimp\n",
      "Sink\n",
      "Skateboard\n",
      "Ski\n",
      "Skirt\n",
      "Skull\n",
      "Skunk\n",
      "Sky\n",
      "Skyscraper\n",
      "Smoke\n",
      "Snail\n",
      "Snake\n",
      "Snow\n",
      "Snowboard\n",
      "Snowman\n",
      "Snowmobile\n",
      "Snowplow\n",
      "Soap dispenser\n",
      "Sock\n",
      "Sofa bed\n",
      "Soil\n",
      "Sombrero\n",
      "Sparrow\n",
      "Spatula\n",
      "Spider\n",
      "Spinach\n",
      "Spoon\n",
      "Sprinkles\n",
      "Squid\n",
      "Squirrel\n",
      "Stapler\n",
      "Starfish\n",
      "Stationary bicycle\n",
      "Steel\n",
      "Stool\n",
      "Stop sign\n",
      "Strawberry\n",
      "Street light\n",
      "Street sign\n",
      "Submarine\n",
      "Sugar\n",
      "Suit\n",
      "Suitcase\n",
      "Sun hat\n",
      "Sunglasses\n",
      "Surfboard\n",
      "Sushi\n",
      "Swan\n",
      "Swimming pool\n",
      "Sword\n",
      "Table\n",
      "Tablet computer\n",
      "Taco\n",
      "Tangerine\n",
      "Tank\n",
      "Taxi\n",
      "Tea\n",
      "Teapot\n",
      "Teddy bear\n",
      "Telephone\n",
      "Television\n",
      "Tennis ball\n",
      "Tennis racket\n",
      "Tent\n",
      "Tiara\n",
      "Tie\n",
      "Tiger\n",
      "Tin can\n",
      "Tire\n",
      "Toaster\n",
      "Toilet\n",
      "Toilet paper\n",
      "Tomato\n",
      "Tongue\n",
      "Tooth\n",
      "Toothbrush\n",
      "Tortoise\n",
      "Towel\n",
      "Tower\n",
      "Toy\n",
      "Traffic light\n",
      "Traffic sign\n",
      "Train\n",
      "Treadmill\n",
      "Tree\n",
      "Tree house\n",
      "Tripod\n",
      "Trousers\n",
      "Truck\n",
      "Trumpet\n",
      "Tulip\n",
      "Turkey\n",
      "Turtle\n",
      "Tuxedo\n",
      "Umbrella\n",
      "Unicycle\n",
      "Van\n",
      "Vase\n",
      "Vegetable\n",
      "Vehicle\n",
      "Violin\n",
      "Volleyball (Ball)\n",
      "Waffle\n",
      "Wall clock\n",
      "Washing machine\n",
      "Watch\n",
      "Water\n",
      "Watermelon\n",
      "Wedding dress\n",
      "Whale\n",
      "Wheel\n",
      "Wheelchair\n",
      "Whisk\n",
      "Whiteboard\n",
      "Willow\n",
      "Window blind\n",
      "Wine\n",
      "Wire\n",
      "Wolf\n",
      "Wood\n",
      "Woodpecker\n",
      "Worm\n",
      "Wrench\n",
      "Zebra\n",
      "Zucchini\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('coda_objects.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    print(f\"{result['display_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5ee23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \n",
    "                \"purple\", \"pink\", \"white\", \"black\", \"gray\", \"brown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ca7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Most {object_areis_pl} <mask>\",\n",
    "    \"Everyone knows that most {object_areis_pl} <mask>.\",\n",
    "    \"Everyone knows that {object_areis_pl} <mask>.\",\n",
    "    \"Commonly {object_areis_pl} <mask>.\",\n",
    "    \"All {object_areis_pl} <mask>.\",\n",
    "    \"It is known that {object_areis_pl} <mask>.\",\n",
    "    \"It's known that {object_areis_pl} <mask>.\",\n",
    "    \"It is known that most {object_areis_pl} <mask>.\",\n",
    "    \"It's known that most {object_areis_pl} <mask>.\",\n",
    "    \"This {object_areis_s} <mask>.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16a075",
   "metadata": {},
   "source": [
    "*Example of instantiated prompt:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c949bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most bananas are <mask>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Most {object_areis_pl} <mask>\".format(\n",
    "    object_areis_pl=\"bananas are\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "523a2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.0479198694229126, 'token': 23318, 'token_str': ' ripe', 'sequence': 'Most bananas are ripe'}, {'score': 0.023059047758579254, 'token': 27532, 'token_str': ' edible', 'sequence': 'Most bananas are edible'}, {'score': 0.02161657065153122, 'token': 35, 'token_str': ':', 'sequence': 'Most bananas are:'}, {'score': 0.019580114632844925, 'token': 5718, 'token_str': ' yellow', 'sequence': 'Most bananas are yellow'}, {'score': 0.01915721222758293, 'token': 34382, 'token_str': ' poisonous', 'sequence': 'Most bananas are poisonous'}]\n"
     ]
    }
   ],
   "source": [
    "print(robertaUnmasker(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c6cb797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ripe', ' edible', ':', ' yellow', ' poisonous', ' sweet', ' bitter', '</s>', '.', ' expensive', ' not', ' delicious', ' bananas', ' black', '…', ' small', ' eaten', ' green', '...', ' a', ' brown', ' grown', ' harvested', ' white', ' red', ' acidic', ' imported', ' …', ' seeds', ' cheap', '.', ' fermented', ' processed', ' toxic', ' sold', ' nutritious', ' bruised', ' dried', ' hard', ' cultivated', ' produced', ' organic', '—', '...', ' :', ' flavored', ',', ' purple', ' available', ' stored', ' in', ' canned', ' soft', ' dry', ' very', ' safe', ' wild', ' protected', ' heavy', ' also', ' fruit', ' fat', ' free', ' sour', ' tasty', ' rotten', ' inexpensive', ' consumed', ' large', ' fruits', ',', ' like', ' strong', ' natural', ' contaminated', ' nuts', ' raw', ' huge', ' tropical', ' frozen', ' good', ' known', ' labeled', ' tough', ' from', ' mixed', ' oily', ' concentrated', ' used', ' growing', ' seasonal', ' sliced', ' preserved', ' healthy', ' planted', ' cooked', ' sticky', ' considered', ' big', ' fast']\n",
      "[0.0479198694229126, 0.023059047758579254, 0.02161657065153122, 0.019580114632844925, 0.01915721222758293, 0.017703471705317497, 0.017541661858558655, 0.015691228210926056, 0.014624605886638165, 0.013484694994986057, 0.012825042009353638, 0.012280110269784927, 0.01168219093233347, 0.011079267598688602, 0.010373681783676147, 0.01037257444113493, 0.010296723805367947, 0.009648222476243973, 0.009577121585607529, 0.009226016700267792, 0.009181251749396324, 0.009067228063941002, 0.00906097050756216, 0.007957177236676216, 0.007859044708311558, 0.007339281029999256, 0.007083444856107235, 0.006590594537556171, 0.006378983613103628, 0.006259039975702763, 0.006257583852857351, 0.006080556195229292, 0.005980260204523802, 0.005827127490192652, 0.00544695882126689, 0.00517978984862566, 0.0051755039021372795, 0.005080805160105228, 0.005039920099079609, 0.0047422670759260654, 0.004724462982267141, 0.004688108339905739, 0.004474192392081022, 0.0042879763059318066, 0.004223816562443972, 0.0041147335432469845, 0.004055734258145094, 0.003884044010192156, 0.0038476926274597645, 0.0036371597088873386, 0.003620230359956622, 0.0035437545739114285, 0.003516364609822631, 0.0034524586517363787, 0.003303218400105834, 0.003212072653695941, 0.0031853620894253254, 0.003173282602801919, 0.0031448067165911198, 0.0030556186102330685, 0.003031851025298238, 0.0029387613758444786, 0.002929828828200698, 0.0029281864408403635, 0.0029001948423683643, 0.0027693177107721567, 0.0027023404836654663, 0.0026995379012078047, 0.002688818611204624, 0.002620447427034378, 0.002523956121876836, 0.0025167164858430624, 0.002489332342520356, 0.0023095039650797844, 0.0022755032405257225, 0.0022673585917800665, 0.002209265949204564, 0.0021367245353758335, 0.002126592444255948, 0.002124135848134756, 0.0020351544953882694, 0.0020263774786144495, 0.0019214653875678778, 0.0018970378441736102, 0.0018770048627629876, 0.0018388965399935842, 0.0018180760089308023, 0.0018156433943659067, 0.001801575650461018, 0.0017979575786739588, 0.0017896846402436495, 0.001786192529834807, 0.0017498346278443933, 0.001748166512697935, 0.0017284195637330413, 0.001717803766950965, 0.0017170504434034228, 0.0017054048366844654, 0.001684732735157013, 0.0016821961617097259]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = robertaUnmasker(prompt, top_k=100)\n",
    "print([pred[\"token_str\"] for pred in predictions1])\n",
    "print([pred[\"score\"] for pred in predictions1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a51198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
