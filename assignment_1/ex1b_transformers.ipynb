{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26be33ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Carina Silberer\"\n",
    "__version__ = \"Multimodal Semantics, IMS Stuttgart, Summer 2023\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63cf5ce5",
   "metadata": {},
   "source": [
    "*Parts of this notebook are based on those of\n",
    "Christopher Potts' notebook of CS224u, Stanford, Spring 2021.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31e0ff7c",
   "metadata": {},
   "source": [
    "# Assignment: Transformer-Based Contexual Representation\n",
    "Documentation: https://huggingface.co/transformers/\n",
    "\n",
    "In this notebook, you will be working with RoBERTa's pre-trained contextual embeddings. We will use the [Hugging Face library](https://huggingface.co), its  `transformers` package and the pre-trained model it provides.\n",
    "\n",
    "If you have never worked with transformers, then go through the Warm-Up. Otherwise you can directly jump to the exercise below. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a773e5fa",
   "metadata": {},
   "source": [
    "## Warm-Up: Basics of `transformers`\n",
    "### Setup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85ee6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except ModuleNotFoundError:\n",
    "    !pip install transformers\n",
    "    # Uncomment the line below if you want to use conda for installation\n",
    "finally:\n",
    "    import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ac5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Uncomment the line bbelow if you cannot import torch (or install it using pip):\n",
    "#!conda install -y pytorch torchvision torchaudio -c pytorch\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28504f01",
   "metadata": {},
   "source": [
    "### RoBERTa\n",
    "#### Loading the model\n",
    "I recommend to use the base model at least to set up everything. If your computing power is limited, then it may be best to stick to the base model for the final results. Otherwise, you may also compare the base model to the capabilities of the large model, by running both on the same examples. \n",
    "* https://huggingface.co/roberta-base\n",
    "* https://huggingface.co/roberta-large\n",
    "\n",
    "***Example Usage: Masked Language Modelling***\n",
    "\n",
    "*Conveniently, with the pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16cdf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f685a95d134140852ecbf4678da9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e756f1e79524a80968c36dc574b1110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b8d1bdf5e84e55a01ce299fc7b4471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5201bb47d3574406be0d5167efb33992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6bee23d60a437e9af963efebc7ea3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "robertaUnmasker = pipeline('fill-mask', model='roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e218a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11639003455638885,\n",
       "  'token': 410,\n",
       "  'token_str': ' little',\n",
       "  'sequence': \"Hello I'm a little gnome.\"},\n",
       " {'score': 0.04736988991498947,\n",
       "  'token': 5192,\n",
       "  'token_str': ' friendly',\n",
       "  'sequence': \"Hello I'm a friendly gnome.\"},\n",
       " {'score': 0.04706908017396927,\n",
       "  'token': 5671,\n",
       "  'token_str': ' garden',\n",
       "  'sequence': \"Hello I'm a garden gnome.\"},\n",
       " {'score': 0.03706818446516991,\n",
       "  'token': 3034,\n",
       "  'token_str': ' computer',\n",
       "  'sequence': \"Hello I'm a computer gnome.\"},\n",
       " {'score': 0.03495142608880997,\n",
       "  'token': 5262,\n",
       "  'token_str': ' tiny',\n",
       "  'sequence': \"Hello I'm a tiny gnome.\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robertaUnmasker(\"Hello I'm a <mask> gnome.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab2b94a7",
   "metadata": {},
   "source": [
    "*Or, if you want to, e.g., extract embeddings or use it in any other customised form*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ee42a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f820165e69b4520a06aa549e3c29d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172ef53536cd4ecbaac8e60fde2aeea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31781d79c526484eb1c7f7406067817e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87382dc23eef48d986cb73b00f35a9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "robertaModel = RobertaModel.from_pretrained('roberta-base')\n",
    "robertaModel.eval()\n",
    "# Side note: You will receive a warning which basically tells you that \n",
    "# some weights were randomly initialised (RoBERTa's classification head),\n",
    "# That is, it tells you to finetune the model if you want to use it for \n",
    "# some supervised inference task (which we don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9b70dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4689884",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am a gnome\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = robertaModel(**encoded_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4607e670",
   "metadata": {},
   "source": [
    "**Q:** *What does the output below, `[1, 768]`, mean?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33641656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"pooler_output\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ca8201",
   "metadata": {},
   "source": [
    "---\n",
    "#### Basics: Tokenisation\n",
    "Documentation: https://huggingface.co/docs/tokenizers/python/latest/ \n",
    "API: https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#tokenizer\n",
    "Let's see what tokenisation does with an input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e452af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Commonly, koalas are black and white\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27bd8134",
   "metadata": {},
   "source": [
    "The `tokenize` method breaks up the input into 'tokens':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e187876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comm', 'only', ',', 'Ġko', 'al', 'as', 'Ġare', 'Ġblack', 'Ġand', 'Ġwhite']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f9299ff",
   "metadata": {},
   "source": [
    "**Q:** *What does the `Ġ` do?*\n",
    "\n",
    "RoBERTa's vocabulary is fixed to a certain number of tokens. Therefore, as you can see above, the tokenizer splits up words that are not part of the vocabulary into smaller subwords and characters ([`word pieces`](https://huggingface.co/transformers/tokenizer_summary.html#wordpiece)). <br/>\n",
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a47e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ban', 'anas']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"bananas\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9452c28",
   "metadata": {},
   "source": [
    "---\n",
    "#### Encoding and Decoding Input\n",
    "The `encode` method maps individual strings to indices into the underlying embedding used by the model. Recall, that BERT has the special tokens `[SEP]`, `[CLS]` (and `[MASK]`for the Masked Language Modeling (MLM))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e60161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 33479, 8338, 6, 12546, 337, 281, 32, 909, 8, 1104, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "ex_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5465b79c",
   "metadata": {},
   "source": [
    "To see what these tokens look like, we can `convert_ids_to_tokens`, i.e., map the ids back to the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a6272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Comm',\n",
       " 'only',\n",
       " ',',\n",
       " 'Ġko',\n",
       " 'al',\n",
       " 'as',\n",
       " 'Ġare',\n",
       " 'Ġblack',\n",
       " 'Ġand',\n",
       " 'Ġwhite',\n",
       " '</s>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(ex_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21a4a38f",
   "metadata": {},
   "source": [
    "The `decode` method maps the indices back to individual strings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a6e213f",
   "metadata": {},
   "source": [
    "### Basics of Representations\n",
    "See also the documentation for more details: https://huggingface.co/transformers/model_doc/bert.html#bertmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d64677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Everyone knows that most bananas are yellow.\"\n",
    "ex_ids = tokenizer.encode(sentence, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccb3f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(ex_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07461ac5",
   "metadata": {},
   "source": [
    "With the `forward` method of the model, we can obtain representations for a batch of example inputs. By setting the optional bool `output_hidden_state` to `True`, the hidden states of all layers are returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95a151e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    reps = robertaModel(input_ids=torch.tensor([ex_ids]), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3b70a66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d0f6447",
   "metadata": {},
   "source": [
    "The return value `reps` is an instance of a special `transformers` class comprising various representations.<br/>\n",
    "To just get the final output representations for each token, we use `last_hidden_state`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cbc8562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b88c0399",
   "metadata": {},
   "source": [
    "As we see from the `shape` of the last hidden state, our batch has 1 example, with 10 tokens, where each token is represented by a vector of dimensionality 768. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5e15356",
   "metadata": {},
   "source": [
    "**Side note:** The `transformers` models also have a `pooler_output` value. \n",
    "In the case of RoBERTa, this is the output representation above the [CLS] token. Recall, **that this is often used as a summary representation for the entire sequence**, on which basis a classification decision is computed.\n",
    "However, __we cannot use `pooler_output` in the current context__, as `transformers` adds new randomised parameters on top of it, to facilitate fine-tuning. (See also the warning message above when loading the model.)<br/>\n",
    "\n",
    "**If we want the [CLS] representation, we need to use `reps.last_hidden_state[:, 0]`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a648e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps.last_hidden_state[:, 0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1234b672",
   "metadata": {},
   "source": [
    "Since we set the `output_hidden_state` to `True`, we can access the output representations from each layer of the model by using `hidden_states`. \n",
    "(Setting `output_hidden_state` to `False` would return  `None`.) <br/>\n",
    "There are 13 layers in total for the RoBERTa-base model, the embeddings, followed by the 12 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81b4c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reps.hidden_states)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dae7a75d",
   "metadata": {},
   "source": [
    "That is,`reps.hidden_states[-1]`would be the same as `reps.hidden_states[12]` for `BERT-base`, and the embeddings can be accessed by `reps.hidden_states[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7fa2c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Everyone knows that most bananas are yellow.</s>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ex_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eedd7ec",
   "metadata": {},
   "source": [
    "## Exercise: Language Perception of Colour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b53a7884",
   "metadata": {},
   "source": [
    "*We will use the data provided by the coda dataset (for Colour Perception)*\n",
    "https://github.com/nala-cub/coda\n",
    "\n",
    "### Instructions\n",
    "* Run the code below. It loads the underlying coda dataset. We will only use the *object names* and *colours* for this exercise.\n",
    "* Choose 20 object names from different categories (e.g., vegetable/fruits, vehicles, ...).\n",
    "* For each object, determine their typical colours from the given list of colours. This is your personal reference output.\n",
    "* Now, get the top colours that RoBERTa predicts for each of these objects, using the prompts below.\n",
    "  * That is, filter the predictions/scores of RoBERTa to contain only a ranking of the target colour terms we consider. \n",
    "  \n",
    "### Taks\n",
    "1. Compute the accuracy of colour prediction using your small reference data. \n",
    "2. Are there objects for which RoBERTa predicts wrong colours? Why could this be the case?\n",
    "3. Summarise in a few sentences your conclusions regarding the colour knowledge one can learn from language use (i.e., large text corpora). \n",
    "\n",
    "***Submit the following files through ILIAS***:\n",
    "* `ex1_transformers_<yourname>.ipynb`: your completed jupyter notebook\n",
    "* `ex1_transformers_<yourname>.[txt|md]`: a plain text file that contains your answers to Tasks 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f8611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('coda_objects.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    # print(result[\"display_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aa0952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_id': '/m/027pcv',\n",
       " 'display_name': 'Zucchini',\n",
       " 'object_s': 'zucchini',\n",
       " 'areis_s': 'is',\n",
       " 'object_pl': 'zucchinis',\n",
       " 'areis_pl': 'are',\n",
       " 'ngram': 'zucchini'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5ee23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \n",
    "                \"purple\", \"pink\", \"white\", \"black\", \"gray\", \"brown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70ca7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Most {object_areis_pl} <mask>\",\n",
    "    \"Everyone knows that most {object_areis_pl} <mask>.\",\n",
    "    \"Everyone knows that {object_areis_pl} <mask>.\",\n",
    "    \"Commonly {object_areis_pl} <mask>.\",\n",
    "    \"All {object_areis_pl} <mask>.\",\n",
    "    \"It is known that {object_areis_pl} <mask>.\",\n",
    "    \"It's known that {object_areis_pl} <mask>.\",\n",
    "    \"It is known that most {object_areis_pl} <mask>.\",\n",
    "    \"It's known that most {object_areis_pl} <mask>.\",\n",
    "    \"This {object_areis_s} <mask>.\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba16a075",
   "metadata": {},
   "source": [
    "*Example of instantiated prompt:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c949bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most bananas are <mask>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Most {object_areis_pl} <mask>\".format(\n",
    "    object_areis_pl=\"bananas are\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "523a2772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.047920264303684235, 'token': 23318, 'token_str': ' ripe', 'sequence': 'Most bananas are ripe'}, {'score': 0.023059150204062462, 'token': 27532, 'token_str': ' edible', 'sequence': 'Most bananas are edible'}, {'score': 0.021616581827402115, 'token': 35, 'token_str': ':', 'sequence': 'Most bananas are:'}, {'score': 0.019579976797103882, 'token': 5718, 'token_str': ' yellow', 'sequence': 'Most bananas are yellow'}, {'score': 0.019157515838742256, 'token': 34382, 'token_str': ' poisonous', 'sequence': 'Most bananas are poisonous'}]\n"
     ]
    }
   ],
   "source": [
    "print(robertaUnmasker(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c6cb797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ripe', ' edible', ':', ' yellow', ' poisonous', ' sweet', ' bitter', '</s>', '.', ' expensive', ' not', ' delicious', ' bananas', ' black', '…', ' small', ' eaten', ' green', '...', ' a', ' brown', ' grown', ' harvested', ' white', ' red', ' acidic', ' imported', ' …', ' seeds', ' cheap', '.', ' fermented', ' processed', ' toxic', ' sold', ' nutritious', ' bruised', ' dried', ' hard', ' cultivated', ' produced', ' organic', '—', '...', ' :', ' flavored', ',', ' purple', ' available', ' stored', ' in', ' canned', ' soft', ' dry', ' very', ' safe', ' wild', ' protected', ' heavy', ' also', ' fruit', ' fat', ' free', ' sour', ' tasty', ' rotten', ' inexpensive', ' consumed', ' large', ' fruits', ',', ' like', ' strong', ' natural', ' contaminated', ' nuts', ' raw', ' huge', ' tropical', ' frozen', ' good', ' known', ' labeled', ' tough', ' from', ' mixed', ' oily', ' concentrated', ' used', ' growing', ' seasonal', ' sliced', ' preserved', ' healthy', ' planted', ' cooked', ' sticky', ' considered', ' big', ' fast']\n",
      "[0.047920264303684235, 0.023059150204062462, 0.021616581827402115, 0.019579976797103882, 0.019157515838742256, 0.0177033469080925, 0.017541538923978806, 0.015691058710217476, 0.014624558389186859, 0.013484703376889229, 0.01282505039125681, 0.01228021178394556, 0.011682153679430485, 0.011079232208430767, 0.010373728349804878, 0.010372660122811794, 0.010296730324625969, 0.009648265317082405, 0.009576980955898762, 0.009225809946656227, 0.009181258268654346, 0.009067234583199024, 0.009061009623110294, 0.00795712135732174, 0.007859019562602043, 0.0073392572812736034, 0.007083422038704157, 0.006590648088604212, 0.006379012018442154, 0.006259043700993061, 0.00625758757814765, 0.006080536637455225, 0.005980241112411022, 0.005827197805047035, 0.0054468996822834015, 0.005179812666028738, 0.005175506696105003, 0.005080827511847019, 0.005039941985160112, 0.004742269869893789, 0.0047244844026863575, 0.004688075743615627, 0.004474178422242403, 0.004287994932383299, 0.004223803523927927, 0.004114752169698477, 0.0040557365864515305, 0.0038840314373373985, 0.0038476656191051006, 0.0036371478345245123, 0.00362020474858582, 0.0035437566693872213, 0.0035163534339517355, 0.00345247401855886, 0.003303207689896226, 0.00321207451634109, 0.0031853518448770046, 0.003173308912664652, 0.003144808579236269, 0.0030555969569832087, 0.0030318645294755697, 0.002938751829788089, 0.0029298083391040564, 0.002928165951743722, 0.002900218591094017, 0.002769340528175235, 0.002702373079955578, 0.0026995395310223103, 0.0026888202410191298, 0.0026204590685665607, 0.002523947972804308, 0.002516689244657755, 0.002489333739504218, 0.002309531904757023, 0.0022754960227757692, 0.0022673511411994696, 0.002209258731454611, 0.0021367340814322233, 0.002126585692167282, 0.00212412909604609, 0.0020351868588477373, 0.0020263788755983114, 0.001921444432809949, 0.0018970462260767817, 0.0018769915914162993, 0.0018388836178928614, 0.0018180840415880084, 0.0018156514270231128, 0.0018015630776062608, 0.0017979656113311648, 0.001789685571566224, 0.0017862071981653571, 0.001749828807078302, 0.0017481609247624874, 0.0017284270143136382, 0.001717798295430839, 0.001717044971883297, 0.001705392962321639, 0.0016847337828949094, 0.0016822036122903228]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = robertaUnmasker(prompt, top_k=100)\n",
    "print([pred[\"token_str\"] for pred in predictions1])\n",
    "print([pred[\"score\"] for pred in predictions1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d743a77",
   "metadata": {},
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60a51198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aircraft',\n",
       " 'Airplane',\n",
       " 'Alarm clock',\n",
       " 'Ambulance',\n",
       " 'Ant',\n",
       " 'Artichoke',\n",
       " 'Apple',\n",
       " 'Apricot',\n",
       " 'Asparagus',\n",
       " 'Auto part']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick 20 objects from the list\n",
    "object_names = []\n",
    "for entry in json_list:\n",
    "    json_obj = json.loads(entry)\n",
    "    object_names.append(json_obj[\"display_name\"])\n",
    "    \n",
    "object_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a004fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20\n",
    "# selected_indexes = np.random.choice(len(object_names), 20)\n",
    "# selected_objects = [object_names[idx] for idx in selected_indexes]\n",
    "# print(selected_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c907cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_objects = ['Ambulance', 'Crow', 'Ketchup', 'Mobile phone', 'Porcupine', 'Apple', 'Microphone', 'Skyscraper', 'Limousine',\n",
    "    'Canoe', 'Light bulb', 'Asparagus', 'Violin', 'Sea turtle', 'Skull', 'Giraffe', 'Traffic Light', 'Drawer', 'Jeans', 'Flashlight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d381b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "target_vocab = [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \n",
    "                \"purple\", \"pink\", \"white\", \"black\", \"gray\", \"brown\"]\n",
    "\"\"\"\n",
    "\n",
    "reference_colors = [\"white\", \"black\", \"red\", \"black\", \"brown\", \"red\", \"black\", \"gray\", \"white\", \"white\", \"yellow\", \"green\", \"black\", \"green\", \"white\", \"yellow\", \"red\", \"white\", \"blue\", \"white\"]\n",
    "\n",
    "assert len(selected_objects) == len(reference_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7030670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(obj_name, targets=target_vocab):\n",
    "    object_areis_pl = f\"{obj_name.lower()}s are\" if obj_name != \"Jeans\" else f\"{obj_name.lower()} are\"\n",
    "    object_areis_s = f\"{obj_name.lower()} is\"\n",
    "    \n",
    "    prompt_templates = [\n",
    "        f\"Most {object_areis_pl} <mask>\",\n",
    "        f\"Everyone knows that most {object_areis_pl} <mask>.\",\n",
    "        f\"Everyone knows that {object_areis_pl} <mask>.\",\n",
    "        f\"Commonly {object_areis_pl} <mask>.\",\n",
    "        f\"All {object_areis_pl} <mask>.\",\n",
    "        f\"It is known that {object_areis_pl} <mask>.\",\n",
    "        f\"It's known that {object_areis_pl} <mask>.\",\n",
    "        f\"It is known that most {object_areis_pl} <mask>.\",\n",
    "        f\"It's known that most {object_areis_pl} <mask>.\",\n",
    "        f\"This {object_areis_s} <mask>.\"\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # prediction for each prompt\n",
    "    predicted_colors_per_prompt = list()\n",
    "    \n",
    "    # iterate and predict\n",
    "    for prompt_template in prompt_templates:\n",
    "        prompt = f\"Most {object_areis_pl} <mask>\"\n",
    "    \n",
    "        preds = robertaUnmasker(prompt, top_k=200)\n",
    "\n",
    "    \n",
    "        # there seems to be an extra whitespace which needs to be removed\n",
    "        pred_tokens = [p[\"token_str\"].strip() for p in preds]\n",
    "    \n",
    "        # already sorted by probability,\n",
    "        # so the first color that matches from the target colors is the prediction\n",
    "        pred_for_this_template = None\n",
    "        \n",
    "        for pt in pred_tokens:\n",
    "            if pt in targets:\n",
    "                pred_for_this_template = pt\n",
    "                break\n",
    "            \n",
    "        predicted_colors_per_prompt.append(pred_for_this_template)\n",
    "        \n",
    "    # sanity check\n",
    "    assert len(prompt_templates) == len(predicted_colors_per_prompt)\n",
    "    \n",
    "    # end\n",
    "    return predicted_colors_per_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "604d3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results per prompt\n",
    "predictions_per_obj = dict()\n",
    "for obj in selected_objects:\n",
    "    predictions_per_obj[obj] = list()\n",
    "    \n",
    "# iterate through obj names and run inference for each prompt\n",
    "for obj_name in selected_objects:\n",
    "    predictions_per_obj[obj_name] = run_inference(obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "768e37dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of correct predictions / length\n",
    "def accuracy_per_obj(target_color, predicted_colors):\n",
    "    buffer = torch.zeros(len(predicted_colors))\n",
    "    \n",
    "    for idx, color in enumerate(predicted_colors):\n",
    "        if color == target_color:\n",
    "            buffer[idx] = 1.0\n",
    "            \n",
    "    acc = torch.count_nonzero(buffer == 1.0) / len(predicted_colors)\n",
    "    return acc\n",
    "\n",
    "\n",
    "accuracy_per_obj(reference_colors[selected_objects.index(\n",
    "    \"Crow\")], predictions_per_obj[\"Crow\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a26d5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Ambulance :: 0.0\n",
      "Accuracy for Crow :: 1.0\n",
      "Accuracy for Ketchup :: 0.0\n",
      "Accuracy for Mobile phone :: 1.0\n",
      "Accuracy for Porcupine :: 0.0\n",
      "Accuracy for Apple :: 1.0\n",
      "Accuracy for Microphone :: 1.0\n",
      "Accuracy for Skyscraper :: 1.0\n",
      "Accuracy for Limousine :: 0.0\n",
      "Accuracy for Canoe :: 0.0\n",
      "Accuracy for Light bulb :: 0.0\n",
      "Accuracy for Asparagus :: 0.0\n",
      "Accuracy for Violin :: 1.0\n",
      "Accuracy for Sea turtle :: 0.0\n",
      "Accuracy for Skull :: 1.0\n",
      "Accuracy for Giraffe :: 0.0\n",
      "Accuracy for Traffic Light :: 1.0\n",
      "Accuracy for Drawer :: 0.0\n",
      "Accuracy for Jeans :: 0.0\n",
      "Accuracy for Flashlight :: 0.0\n",
      "\n",
      "Mean Accuracy :: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "all_acc = torch.zeros(20)\n",
    "\n",
    "# collect the wrong ones for analysis\n",
    "wrong_predictions = list()\n",
    "\n",
    "for idx, obj_name in enumerate(selected_objects):\n",
    "    acc = accuracy_per_obj(\n",
    "        reference_colors[idx], predictions_per_obj[obj_name]\n",
    "    )\n",
    "    print(f\"Accuracy for {obj_name} :: {acc}\")\n",
    "    all_acc[idx] = acc\n",
    "    \n",
    "    if acc == 0.0:\n",
    "        wrong_predictions.append(obj_name)\n",
    "\n",
    "print()\n",
    "print(f\"Mean Accuracy :: {all_acc.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfcc0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
